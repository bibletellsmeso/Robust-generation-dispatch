import pandas as pd
import numpy as np
import glob
import os
import matplotlib.pyplot as plt
import seaborn as sns

# ğŸ“Œ ë°ì´í„° ê²½ë¡œ ì„¤ì • (ê²½ë¡œ ìˆ˜ì •)
data_folder = r"C:\Users\Andrew\OneDrive\Second brain\Programming\Python\Optimization\Robust generation dispatch\data"
path_pattern = os.path.join(data_folder, "25109_21.29_-157.86_*.csv")  # ëª¨ë“  CSV íŒŒì¼ ì°¾ê¸°

# ğŸ“Œ íƒœì–‘ê´‘ ë°œì „ëŸ‰ ê³„ì‚° ê³µì‹
def calculate_pv_generation(E, T, E0=1000, P0=600, T0=25, gamma_P=-0.0035):
    pv_power = (E / E0) * P0 * (1 + gamma_P * (T - T0))
    pv_power = np.clip(pv_power, 0, P0)  # 0W ~ 600W ë²”ìœ„ë¡œ ì œí•œ
    return pv_power

# ğŸ“Œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ë³‘í•©
def load_and_merge_data(path_pattern):
    files = glob.glob(path_pattern)  # íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    all_data = []

    print(f"ğŸ” ì°¾ì€ íŒŒì¼ ê°œìˆ˜: {len(files)}")
    if len(files) == 0:
        print("âŒ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None

    for file in files:
        try:
            file_size = os.path.getsize(file)  # íŒŒì¼ í¬ê¸° í™•ì¸
            if file_size == 0:
                print(f"âš ï¸ ê²½ê³ : {file} íŒŒì¼ì´ ë¹„ì–´ ìˆìŒ. ê±´ë„ˆëœ€.")
                continue  # ë¹ˆ íŒŒì¼ì€ ê±´ë„ˆë›´ë‹¤.

            df = pd.read_csv(file, skiprows=1)  # ì²« ë²ˆì§¸ í–‰ì„ ë²„ë¦¬ê³  ë‘ ë²ˆì§¸ í–‰ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì‚¬ìš©
            df.columns = df.iloc[0]  # ì´í›„ ì²« ë²ˆì§¸ í–‰ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì„¤ì •
            df = df[1:].reset_index(drop=True)  # ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì„¤ì •í•œ ë’¤ ì²« ë²ˆì§¸ í–‰ ì œê±°
            df = df.apply(pd.to_numeric, errors='ignore')  # ë°ì´í„° ë³€í™˜
            df['datetime'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour', 'Minute']])  # datetime ì»¬ëŸ¼ ìƒì„± (Local Time ê¸°ì¤€)
            df = df.dropna(axis=1, how='all')  # ë¶ˆí•„ìš”í•œ NaN ì»¬ëŸ¼ ì œê±°
            df['pv_power'] = calculate_pv_generation(df['GHI'], df['Temperature'])  # ë°œì „ëŸ‰ ê³„ì‚° (GHIë¥¼ Eë¡œ ì‚¬ìš©)
            df = df[['datetime', 'GHI', 'Temperature', 'pv_power']]  # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ

            all_data.append(df)
            print(f"âœ… íŒŒì¼ ë¡œë“œ ì„±ê³µ: {file}, ë°ì´í„° ê°œìˆ˜: {len(df)}")

        except Exception as e:
            print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file}, ì˜¤ë¥˜: {e}")

    if len(all_data) == 0:
        print("âŒ ëª¨ë“  íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œì™€ íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None

    merged_df = pd.concat(all_data, ignore_index=True)
    print(f"ğŸ“Š ì´ ë°ì´í„° ê°œìˆ˜: {len(merged_df)}")
    print(f"ğŸ“Œ ë°ì´í„° ìµœì†Œ/ìµœëŒ€ ì‹œê°„: {merged_df['datetime'].min()} ~ {merged_df['datetime'].max()}")
    return merged_df

# ğŸ“Œ 15ë¶„ ë‹¨ìœ„ë¡œ ë³´ê°„ + ëˆ„ë½ëœ ì‹œê°„ ì¶”ê°€
def resample_to_15min(data):
    full_time_range = pd.date_range(start=data['datetime'].min().floor('D'),
                                    end=data['datetime'].max().ceil('D'),
                                    freq='15T')
    print(f"ğŸ“Œ ë³´ê°„ëœ ì‹œê°„ ë²”ìœ„: {full_time_range.min()} ~ {full_time_range.max()}")
    
    data = data.set_index('datetime').reindex(full_time_range).interpolate().reset_index()
    data.rename(columns={'index': 'datetime'}, inplace=True)
    
    data.fillna(0, inplace=True)  # NaN ê°’ì´ ìˆë‹¤ë©´ 0ìœ¼ë¡œ ì±„ìš°ê¸° (íƒœì–‘ê´‘ ë°œì „ëŸ‰ì´ ì—†ë˜ ì‹œê°„ë„ í¬í•¨)
    
    return data

# ğŸ“Œ ë¶ˆëŒ€ì¹­ì„±ì„ ë°˜ì˜í•œ Â±ì‹œê·¸ë§ˆ(ì‹ ë¢°êµ¬ê°„) ê³„ì‚° í•¨ìˆ˜
def calculate_sigma_stats(data):
    # helper í•¨ìˆ˜: ì£¼ì–´ì§„ ì‹œë¦¬ì¦ˆì—ì„œ í‰ê· , ì–‘ì¸¡(í‰ê· ë³´ë‹¤ í°/ì‘ì€) í‘œì¤€í¸ì°¨ë¥¼ êµ¬í•œ í›„,
    # multiplierë¥¼ ê³±í•˜ì—¬ í•˜í•œê³¼ ìƒí•œì„ ì‚°ì¶œ
    def compute_bounds(series, multiplier):
        m = series.mean()
        # í‰ê· ë³´ë‹¤ í° ê°’ë“¤ì˜ í‘œì¤€í¸ì°¨ (ì–‘ì¸¡ ì‹œê·¸ë§ˆ)
        pos_data = series[series > m]
        pos_std = pos_data.std() if len(pos_data) > 1 else 0
        # í‰ê· ë³´ë‹¤ ì‘ì€ ê°’ë“¤ì˜ í‘œì¤€í¸ì°¨ (ìŒì¸¡ ì‹œê·¸ë§ˆ)
        neg_data = series[series < m]
        neg_std = neg_data.std() if len(neg_data) > 1 else 0
        lower_bound = m - multiplier * neg_std
        upper_bound = m + multiplier * pos_std
        return m, lower_bound, upper_bound, pos_std, neg_std

    # ê·¸ë£¹ë³„(ê° ì‹œê°„ëŒ€)ë¡œ PV ë°œì „ëŸ‰ì— ëŒ€í•´ Â±2ì‹œê·¸ë§ˆ ë²”ìœ„ ì‚°ì¶œ
    pv_stats_list = []
    for t, group in data.groupby(data['datetime'].dt.time):
        m, lower_bound, upper_bound, pos_std, neg_std = compute_bounds(group['pv_power'], multiplier=2)
        pv_stats_list.append({
            'time': t,
            'mean': m,
            'lower_2sigma': lower_bound,
            'upper_2sigma': upper_bound,
            'pos_std': pos_std,
            'neg_std': neg_std,
            'std': group['pv_power'].std()  # ì „ì²´ í‘œì¤€í¸ì°¨
        })
    pv_stats = pd.DataFrame(pv_stats_list).set_index('time')

    # ë¨í•‘: ë°œì „ëŸ‰ì˜ ì‹œê³„ì—´ ì°¨ë¶„ìœ¼ë¡œ ê³„ì‚°
    # ì£¼ì˜: diff()ë¡œ ì¸í•´ í•˜ë£¨ ë‚´ 15ë¶„ ê°„ê²© ë°œì „ëŸ‰ì€ 96ê°œì¸ë°, ë¨í•‘ì€ ìì—°ìŠ¤ëŸ½ê²Œ 95ê°œê°€ ë¨.
    data['ramping'] = data['pv_power'].diff()
    
    ramping_stats_list = []
    for t, group in data.groupby(data['datetime'].dt.time):
        # diff()ë¡œ ì¸í•´ NaNì´ í¬í•¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ drop
        valid_ramping = group['ramping'].dropna()
        if len(valid_ramping) == 0:
            m = np.nan
            lower_bound = np.nan
            upper_bound = np.nan
            pos_std = np.nan
            neg_std = np.nan
        else:
            m, lower_bound, upper_bound, pos_std, neg_std = compute_bounds(valid_ramping, multiplier=3)
        ramping_stats_list.append({
            'time': t,
            'mean': m,
            'lower_3sigma': lower_bound,
            'upper_3sigma': upper_bound,
            'pos_std': pos_std,
            'neg_std': neg_std,
            'std': valid_ramping.std()
        })
    ramping_stats = pd.DataFrame(ramping_stats_list).set_index('time')

    return pv_stats, ramping_stats

# ğŸ“Œ 96ê°œ íƒ€ì„ìŠ¤í…ë³„ ë°œì „ëŸ‰ê³¼ 95ê°œ(ìì—°ì‚°ì¶œ)ì˜ ë¨í•‘ ë¶„í¬ ì‹œê°í™” í•¨ìˆ˜
def plot_combined_distributions(data):
    data['ramping'] = data['pv_power'].diff()
    time_steps = data['datetime'].dt.time.unique()
    
    plt.figure(figsize=(12, 6))
    for time in time_steps:
        subset = data[data['datetime'].dt.time == time]
        sns.kdeplot(subset['pv_power'], label=str(time), alpha=0.5)
    plt.xlabel("PV Power Generation (W)")
    plt.ylabel("Density")
    plt.title("Probability Distributions of PV Power for 96 Time Steps")
    plt.legend(loc='upper right', fontsize=6, ncol=4)
    plt.grid(True)
    plt.show()
    
    plt.figure(figsize=(12, 6))
    for time in time_steps:
        subset = data[data['datetime'].dt.time == time]
        sns.kdeplot(subset['ramping'].dropna(), label=str(time), alpha=0.5)
    plt.xlabel("Ramping (Î”PV Power, W)")
    plt.ylabel("Density")
    plt.title("Ramping Distributions for 96 Time Steps (ì‹¤ì œ ë°ì´í„°ëŠ” í•˜ë£¨ 95ê°œ)")
    plt.legend(loc='upper right', fontsize=6, ncol=4)
    plt.grid(True)
    plt.show()

# ğŸ“Œ ì‹¤í–‰ ì½”ë“œ
merged_data = load_and_merge_data(path_pattern)

if merged_data is not None:
    merged_data = resample_to_15min(merged_data)
    pv_stats_local, ramping_stats_local = calculate_sigma_stats(merged_data)
    
    print("----- PV Power Statistics (ê° ì‹œê°„ëŒ€ Â±2ì‹œê·¸ë§ˆ) -----")
    print(pv_stats_local.to_string())
    
    print("----- Ramping Statistics (ê° ì‹œê°„ëŒ€ Â±3ì‹œê·¸ë§ˆ) -----")
    print(ramping_stats_local.to_string())
    
    plot_combined_distributions(merged_data)
    
    pv_stats_local.to_pickle("pv_stats_local.pkl")
    ramping_stats_local.to_pickle("ramping_stats_local.pkl")
