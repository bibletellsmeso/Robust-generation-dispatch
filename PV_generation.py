import pandas as pd
import numpy as np
import glob
import os
import matplotlib.pyplot as plt
import seaborn as sns

# ğŸ“Œ ë°ì´í„° ê²½ë¡œ ì„¤ì • (ê²½ë¡œ ìˆ˜ì •)
data_folder = r"C:\Users\Andrew\OneDrive\Second brain\Programming\Python\Optimization\Robust generation dispatch\data"
path_pattern = os.path.join(data_folder, "25109_21.29_-157.86_*.csv")  # ëª¨ë“  CSV íŒŒì¼ ì°¾ê¸°

# ğŸ“Œ íƒœì–‘ê´‘ ë°œì „ëŸ‰ ê³„ì‚° ê³µì‹
def calculate_pv_generation(E, T, E0=1000, P0=600, T0=25, gamma_P=-0.0035):
    pv_power = (E / E0) * P0 * (1 + gamma_P * (T - T0))
    pv_power = np.clip(pv_power, 0, P0)  # 0W ~ 600W ë²”ìœ„ë¡œ ì œí•œ
    return pv_power

# ğŸ“Œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ë³‘í•©
def load_and_merge_data(path_pattern):
    files = glob.glob(path_pattern)  # íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    all_data = []

    print(f"ğŸ” ì°¾ì€ íŒŒì¼ ê°œìˆ˜: {len(files)}")
    if len(files) == 0:
        print("âŒ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None

    for file in files:
        try:
            file_size = os.path.getsize(file)  # íŒŒì¼ í¬ê¸° í™•ì¸
            if file_size == 0:
                print(f"âš ï¸ ê²½ê³ : {file} íŒŒì¼ì´ ë¹„ì–´ ìˆìŒ. ê±´ë„ˆëœ€.")
                continue  # ë¹ˆ íŒŒì¼ì€ ê±´ë„ˆë›´ë‹¤.

            df = pd.read_csv(file, skiprows=1)  # ì²« ë²ˆì§¸ í–‰ì„ ë²„ë¦¬ê³  ë‘ ë²ˆì§¸ í–‰ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì‚¬ìš©
            df.columns = df.iloc[0]  #  ì´í›„ ì²« ë²ˆì§¸ í–‰ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì„¤ì •
            df = df[1:].reset_index(drop=True)  # ì»¬ëŸ¼ëª…ìœ¼ë¡œ ì„¤ì •í•œ ë’¤ ì²« ë²ˆì§¸ í–‰ ì œê±°
            df = df.apply(pd.to_numeric, errors='ignore')  # ë°ì´í„° ë³€í™˜
            df['datetime'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour', 'Minute']])  # datetime ì»¬ëŸ¼ ìƒì„± (Local Time ê¸°ì¤€)
            df = df.dropna(axis=1, how='all')  # ë¶ˆí•„ìš”í•œ NaN ì»¬ëŸ¼ ì œê±°
            df['pv_power'] = calculate_pv_generation(df['GHI'], df['Temperature'])  # ë°œì „ëŸ‰ ê³„ì‚° (GHIë¥¼ Eë¡œ ì‚¬ìš©)
            df = df[['datetime', 'GHI', 'Temperature', 'pv_power']]  # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ

            all_data.append(df)
            print(f"âœ… íŒŒì¼ ë¡œë“œ ì„±ê³µ: {file}, ë°ì´í„° ê°œìˆ˜: {len(df)}")

        except Exception as e:
            print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file}, ì˜¤ë¥˜: {e}")

    if len(all_data) == 0:
        print("âŒ ëª¨ë“  íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œì™€ íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None

    merged_df = pd.concat(all_data, ignore_index=True)
    print(f"ğŸ“Š ì´ ë°ì´í„° ê°œìˆ˜: {len(merged_df)}")
    print(f"ğŸ“Œ ë°ì´í„° ìµœì†Œ/ìµœëŒ€ ì‹œê°„: {merged_df['datetime'].min()} ~ {merged_df['datetime'].max()}")
    return merged_df

# ğŸ“Œ 15ë¶„ ë‹¨ìœ„ë¡œ ë³´ê°„ + ëˆ„ë½ëœ ì‹œê°„ ì¶”ê°€
def resample_to_15min(data):
    full_time_range = pd.date_range(start=data['datetime'].min().floor('D'),
                                    end=data['datetime'].max().ceil('D'),
                                    freq='15T')
    print(f"ğŸ“Œ ë³´ê°„ëœ ì‹œê°„ ë²”ìœ„: {full_time_range.min()} ~ {full_time_range.max()}")
    
    data = data.set_index('datetime').reindex(full_time_range).interpolate().reset_index()
    data.rename(columns={'index': 'datetime'}, inplace=True)
    
    data.fillna(0, inplace=True) # NaN ê°’ì´ ìˆë‹¤ë©´ 0ìœ¼ë¡œ ì±„ìš°ê¸° (íƒœì–‘ê´‘ ë°œì „ëŸ‰ì´ ì—†ë˜ ì‹œê°„ë„ í¬í•¨)
    
    return data

# ğŸ“Œ Â±1.96Ïƒ, Â±2.58Ïƒ í†µê³„ ê³„ì‚° í•¨ìˆ˜
def calculate_sigma_stats(data):
    unique_times = data['datetime'].dt.time.unique()
    print(f"ğŸ“Œ ê·¸ë£¹í™”ëœ ì‹œê°„ ê°œìˆ˜: {len(unique_times)}ê°œ")

    epsilon = 1e-6

    pv_stats = data.groupby(data['datetime'].dt.time)['pv_power'].agg(['mean', 'std'])
    pv_stats['-1.96sigma'] = (pv_stats['mean'] - 1.96 * pv_stats['std'])
    pv_stats['+1.96sigma'] = pv_stats['mean'] + 1.96 * pv_stats['std']

    pv_stats['-1.96sigma_scaled'] = pv_stats['-1.96sigma'] / np.maximum(pv_stats['mean'], epsilon)
    pv_stats['+1.96sigma_scaled'] = pv_stats['+1.96sigma'] / np.maximum(pv_stats['mean'], epsilon)

    data['ramping'] = data['pv_power'].diff()
    ramping_stats = data.groupby(data['datetime'].dt.time)['ramping'].agg(['mean', 'std'])
    ramping_stats['-1.96sigma'] = ramping_stats['mean'] - 1.96 * ramping_stats['std']
    ramping_stats['+1.96sigma'] = ramping_stats['mean'] + 1.96 * ramping_stats['std']
    ramping_stats['-2.58sigma'] = ramping_stats['mean'] - 3 * ramping_stats['std']
    ramping_stats['+2.58sigma'] = ramping_stats['mean'] + 3 * ramping_stats['std']

    ramping_stats['-1.96sigma_scaled'] = ramping_stats['-1.96sigma'] / np.maximum(ramping_stats['mean'], epsilon)
    ramping_stats['+1.96sigma_scaled'] = ramping_stats['+1.96sigma'] / np.maximum(ramping_stats['mean'], epsilon)
    ramping_stats['-2.58sigma_scaled'] = ramping_stats['-2.58sigma'] / np.maximum(ramping_stats['mean'], epsilon)
    ramping_stats['+2.58sigma_scaled'] = ramping_stats['+2.58sigma'] / np.maximum(ramping_stats['mean'], epsilon)

    return pv_stats, ramping_stats

# ğŸ“Œ 96ê°œ íƒ€ì„ ìŠ¤í…ë³„ í™•ë¥  ë¶„í¬ ë° ë¨í•‘ ë¶„ì„ í•¨ìˆ˜
def plot_combined_distributions(data):
    data['ramping'] = data['pv_power'].diff()
    time_steps = data['datetime'].dt.time.unique()
    
    plt.figure(figsize=(12, 6))
    for time in time_steps:
        subset = data[data['datetime'].dt.time == time]
        sns.kdeplot(subset['pv_power'], label=str(time), alpha=0.5)
    plt.xlabel("PV Power Generation (W)")
    plt.ylabel("Density")
    plt.title("Probability Distributions of PV Power for 96 Time Steps")
    plt.legend(loc='upper right', fontsize=6, ncol=4)
    plt.grid(True)
    plt.show()
    
    plt.figure(figsize=(12, 6))
    for time in time_steps:
        subset = data[data['datetime'].dt.time == time]
        sns.kdeplot(subset['ramping'].dropna(), label=str(time), alpha=0.5)
    plt.xlabel("Ramping (Î”PV Power, W)")
    plt.ylabel("Density")
    plt.title("Ramping Distributions for 96 Time Steps")
    plt.legend(loc='upper right', fontsize=6, ncol=4)
    plt.grid(True)
    plt.show()

# ğŸ“Œ ì‹¤í–‰ ì½”ë“œ
merged_data = load_and_merge_data(path_pattern)

if merged_data is not None:
    merged_data = resample_to_15min(merged_data)
    pv_stats_local, ramping_stats_local = calculate_sigma_stats(merged_data)
    print(pv_stats_local.to_string())
    print(ramping_stats_local.to_string())
    plot_combined_distributions(merged_data)
    pv_stats_local.to_pickle("pv_stats_local.pkl")
    ramping_stats_local.to_pickle("ramping_stats_local.pkl")